{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fine-tuning Audio Spectogram Transformer to GTZAN\n",
        "\n",
        "This notebook was inspired by:\n",
        "https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/audio_classification.ipynb#scrollTo=5WMEawzyCEyG\n",
        "\n",
        "See also the original paper: https://arxiv.org/abs/2104.01778\n",
        "\n",
        "See also Huggingface: https://huggingface.co/docs/transformers/v4.40.0/en/model_doc/audio-spectrogram-transformer#transformers.ASTConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T18:52:05.329309Z",
          "iopub.status.busy": "2024-04-21T18:52:05.328949Z",
          "iopub.status.idle": "2024-04-21T18:52:26.464091Z",
          "shell.execute_reply": "2024-04-21T18:52:26.46313Z",
          "shell.execute_reply.started": "2024-04-21T18:52:05.329277Z"
        },
        "id": "q45Zj4aGtNno",
        "outputId": "b3c464eb-52fb-4d42-f323-9431d01dba12",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import AutoFeatureExtractor, ASTForAudioClassification, AutoModelForAudioClassification, TrainingArguments, Trainer, get_scheduler\n",
        "from datasets import load_dataset, Audio, load_metric\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from tqdm.auto import tqdm\n",
        "import torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T18:52:26.466426Z",
          "iopub.status.busy": "2024-04-21T18:52:26.465868Z",
          "iopub.status.idle": "2024-04-21T18:52:26.470691Z",
          "shell.execute_reply": "2024-04-21T18:52:26.469651Z",
          "shell.execute_reply.started": "2024-04-21T18:52:26.466399Z"
        },
        "id": "DwZ-Tn1UtNns",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "SEED = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "4951b05f9b6246c0aaabef992c77c8b5",
            "d452944ee61b477dbbb846afb8533ceb",
            "23b5ab82651b4e00bfacc71dfc6420cd",
            "cf0824b953744085906a496dd53b7766"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-04-21T18:52:26.47225Z",
          "iopub.status.busy": "2024-04-21T18:52:26.471928Z",
          "iopub.status.idle": "2024-04-21T18:53:06.246493Z",
          "shell.execute_reply": "2024-04-21T18:53:06.245406Z",
          "shell.execute_reply.started": "2024-04-21T18:52:26.472224Z"
        },
        "id": "wROj4nImtNnu",
        "outputId": "ff81adf8-ce3c-471a-fa54-d5f0e5f928ea",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#https://huggingface.co/datasets/marsyas/gtzan\n",
        "df_raw = load_dataset(\"marsyas/gtzan\", trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T18:53:06.249735Z",
          "iopub.status.busy": "2024-04-21T18:53:06.249426Z",
          "iopub.status.idle": "2024-04-21T18:53:06.271933Z",
          "shell.execute_reply": "2024-04-21T18:53:06.270786Z",
          "shell.execute_reply.started": "2024-04-21T18:53:06.249709Z"
        },
        "id": "NOc0flPqtNnv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df_raw = df_raw['train'].train_test_split(seed = SEED, shuffle = True,\n",
        "                                  test_size = .2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T18:53:06.276188Z",
          "iopub.status.busy": "2024-04-21T18:53:06.275831Z",
          "iopub.status.idle": "2024-04-21T18:53:21.069958Z",
          "shell.execute_reply": "2024-04-21T18:53:21.068749Z",
          "shell.execute_reply.started": "2024-04-21T18:53:06.276157Z"
        },
        "id": "QRNiotTBtNnw",
        "outputId": "96676523-bd15-4fda-a340-31f3da99bccc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Obtaining human-readable label\n",
        "id2label_function = df_raw['train'].features['genre'].int2str\n",
        "print(\"genre: \", id2label_function(df_raw['train'][0]['genre']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T18:53:21.07217Z",
          "iopub.status.busy": "2024-04-21T18:53:21.071491Z",
          "iopub.status.idle": "2024-04-21T18:53:21.10018Z",
          "shell.execute_reply": "2024-04-21T18:53:21.099319Z",
          "shell.execute_reply.started": "2024-04-21T18:53:21.072143Z"
        },
        "id": "d7bKvPFHtNny",
        "outputId": "1569494e-5958-41c4-f8c1-5364c79fc73b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "sampling_rate_check = None\n",
        "all_same = True\n",
        "\n",
        "# Iterating through each sample\n",
        "for set_name in ['train', 'test']: # Iterating through both sets\n",
        "    for sample in df_raw[set_name]:\n",
        "        sampling_rate = sample['audio']['sampling_rate']\n",
        "\n",
        "        if sampling_rate_check is None:\n",
        "            sampling_rate_check = sampling_rate\n",
        "        else:\n",
        "            if sampling_rate != sampling_rate_check:\n",
        "                all_same = False\n",
        "            break\n",
        "\n",
        "# Printing result\n",
        "if all_same:\n",
        "    print(f\"All samples have the same sampling rate: {sampling_rate_check} Hz\")\n",
        "else:\n",
        "    print(\"The samples in the dataframe have different sampling rates.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkYENj92tNnz"
      },
      "source": [
        "## Feature extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We load the Audio Spectogram Transformer which has been pretrained on audioset. This corresponds to model 1. in the section *Pretrained Models* on the Github of the original paper.\n",
        "https://github.com/YuanGongND/ast/tree/master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T18:53:21.10147Z",
          "iopub.status.busy": "2024-04-21T18:53:21.101185Z",
          "iopub.status.idle": "2024-04-21T18:53:21.106054Z",
          "shell.execute_reply": "2024-04-21T18:53:21.105061Z",
          "shell.execute_reply.started": "2024-04-21T18:53:21.101444Z"
        },
        "id": "Ne9fNe-dtNn1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model_checkpoint = \"MIT/ast-finetuned-audioset-10-10-0.4593\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use the feature extractor from Huggingface, which extracts mel-filter bank faetures from raw speech, pads/truncates them to a fixed length, and normalises them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "7ab93d040e884651aadf08e3a869f6be"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-04-21T18:53:21.107827Z",
          "iopub.status.busy": "2024-04-21T18:53:21.107387Z",
          "iopub.status.idle": "2024-04-21T18:53:21.970969Z",
          "shell.execute_reply": "2024-04-21T18:53:21.970118Z",
          "shell.execute_reply.started": "2024-04-21T18:53:21.107795Z"
        },
        "id": "Zy5CGUnZtNn2",
        "outputId": "2164951b-d95a-47fe-e7f7-362f9bb6f6b4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We ensure that the data has the same sampling rate of 16.000 which is the sampling rate of the AST."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T18:53:21.972414Z",
          "iopub.status.busy": "2024-04-21T18:53:21.972115Z",
          "iopub.status.idle": "2024-04-21T18:53:21.984437Z",
          "shell.execute_reply": "2024-04-21T18:53:21.983634Z",
          "shell.execute_reply.started": "2024-04-21T18:53:21.972388Z"
        },
        "id": "OxPM38TrtNn3",
        "outputId": "b64a255a-aa21-477e-cab1-46b73d5a21c3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "sampling_rate = feature_extractor.sampling_rate\n",
        "print(f'AST sampling rate: {sampling_rate} Hz')\n",
        "\n",
        "# Resampling data\n",
        "df_raw = df_raw.cast_column(\"audio\", Audio(sampling_rate = 16000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7W2M3wNtNn4"
      },
      "source": [
        "The number of data-points in the array of the audio-files is not exactly the same. So in the feature-extractor we set max_length to 30 seconds and truncate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T18:53:21.988223Z",
          "iopub.status.busy": "2024-04-21T18:53:21.987916Z",
          "iopub.status.idle": "2024-04-21T18:53:21.995015Z",
          "shell.execute_reply": "2024-04-21T18:53:21.994009Z",
          "shell.execute_reply.started": "2024-04-21T18:53:21.9882Z"
        },
        "id": "Ttxo6W3VtNn4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "max_duration = 30.0 # 30 seconds\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    # Extracting and saving arrays\n",
        "    audio_arrays = [x['array'] for x in examples['audio']]\n",
        "\n",
        "    # Preprocessing audio inputs\n",
        "    inputs = feature_extractor(audio_arrays,\n",
        "                              sampling_rate = feature_extractor.sampling_rate,\n",
        "                              return_tensors=\"pt\", # output pytorch tensors\n",
        "                              max_length = int(feature_extractor.sampling_rate * max_duration),\n",
        "                              truncation = True)\n",
        "\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "0d19ee73ec3f472b905842bb09ae3438",
            "e3d6a9f7e47344a48a56945302efe6ad"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-04-21T18:53:21.996329Z",
          "iopub.status.busy": "2024-04-21T18:53:21.996058Z",
          "iopub.status.idle": "2024-04-21T18:54:04.867267Z",
          "shell.execute_reply": "2024-04-21T18:54:04.866347Z",
          "shell.execute_reply.started": "2024-04-21T18:53:21.996307Z"
        },
        "id": "bXjxzLxTtNn5",
        "outputId": "d1a914bb-cd3e-47ff-9cc4-88a1189984a4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df = df_raw.map(preprocess_function,\n",
        "                   remove_columns = ['audio', 'file'],\n",
        "                   batched = True,\n",
        "                   batch_size = 100,\n",
        "                   num_proc = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T18:54:04.869236Z",
          "iopub.status.busy": "2024-04-21T18:54:04.868482Z",
          "iopub.status.idle": "2024-04-21T18:54:05.063239Z",
          "shell.execute_reply": "2024-04-21T18:54:05.062381Z",
          "shell.execute_reply.started": "2024-04-21T18:54:04.869209Z"
        },
        "id": "7mBWe9vttNn5",
        "outputId": "2d650cc0-96ae-4a7d-e082-539b64099c8b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(f\"Size of spectogram: {len(df['train'][0]['input_values'][0])}, {len(df['train'][0]['input_values'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T18:54:05.425464Z",
          "iopub.status.busy": "2024-04-21T18:54:05.42508Z",
          "iopub.status.idle": "2024-04-21T18:54:05.431678Z",
          "shell.execute_reply": "2024-04-21T18:54:05.430876Z",
          "shell.execute_reply.started": "2024-04-21T18:54:05.425438Z"
        },
        "id": "H4bfApxEtNn6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Renaming genre column\n",
        "df = df.rename_column('genre', 'labels')\n",
        "\n",
        "# Id to label\n",
        "id2label = {str(i): id2label_function(i)\n",
        "           for i in range(len(df['train'].features['labels'].names))}\n",
        "\n",
        "# Label to id\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "#Check that is works\n",
        "integer = 8 # Defining a random int\n",
        "label = id2label[str(integer)] # Obtaining label\n",
        "\n",
        "print(f'\\nId: {integer}')\n",
        "print(f'\\nLabel: {label}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP4-_ithtNn6"
      },
      "source": [
        "## Fine-tune using Torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We load the pretrained AST model that we are going to fine-tune to classify music genres in GTZAN.\n",
        "\n",
        "The output complains about mismathing sizes in the pretrained model, which was pretrained on 527 classes, and the model for GTZAN which only has 10 classes. This means that we need to fine-tune the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "501fbb5d65f14c199ce6a762c75cff69",
            "f834529f070b44c4bdb5b0f716787bf4"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-04-21T18:54:05.443929Z",
          "iopub.status.busy": "2024-04-21T18:54:05.443674Z",
          "iopub.status.idle": "2024-04-21T18:54:08.969678Z",
          "shell.execute_reply": "2024-04-21T18:54:08.968856Z",
          "shell.execute_reply.started": "2024-04-21T18:54:05.443908Z"
        },
        "id": "eLuqBfq6tNn6",
        "outputId": "36c3c884-eda6-43ea-bb1e-969bbdc41f95",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "num_labels = len(id2label) # Obtaining the total number of labels\n",
        "\n",
        "# Loading model\n",
        "ast_model = AutoModelForAudioClassification.from_pretrained(model_checkpoint,\n",
        "                                                         num_labels = num_labels,\n",
        "                                                         label2id=label2id,\n",
        "                                                         id2label=id2label,\n",
        "                                                         ignore_mismatched_sizes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T18:54:08.971026Z",
          "iopub.status.busy": "2024-04-21T18:54:08.970741Z",
          "iopub.status.idle": "2024-04-21T18:54:08.976141Z",
          "shell.execute_reply": "2024-04-21T18:54:08.975142Z",
          "shell.execute_reply.started": "2024-04-21T18:54:08.971002Z"
        },
        "id": "aiBWrMEVtNn8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.set_format(\"torch\")\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "ast_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T18:54:08.990024Z",
          "iopub.status.busy": "2024-04-21T18:54:08.989444Z",
          "iopub.status.idle": "2024-04-21T18:54:08.997191Z",
          "shell.execute_reply": "2024-04-21T18:54:08.996453Z",
          "shell.execute_reply.started": "2024-04-21T18:54:08.989999Z"
        },
        "id": "ShOhCqbMtNn8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Set up data-loaders so we can train in batches\n",
        "train_dataloader = DataLoader(df['train'], shuffle=True, batch_size=8)\n",
        "eval_dataloader = DataLoader(df['test'], batch_size=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T18:56:05.288866Z",
          "iopub.status.busy": "2024-04-21T18:56:05.288483Z",
          "iopub.status.idle": "2024-04-21T18:56:05.29402Z",
          "shell.execute_reply": "2024-04-21T18:56:05.292973Z",
          "shell.execute_reply.started": "2024-04-21T18:56:05.288839Z"
        },
        "id": "6XJoIZ1FtNn8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Setting up fine-tuning training hyperparams\n",
        "optimizer = AdamW(ast_model.parameters(), lr=5e-5) # set Adam as optimizer\n",
        "\n",
        "num_epochs = 20\n",
        "num_training_steps = num_epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We fine-tune the model using Kaggle's GPU T4 x2 for 20 epochs, which took 1 hour and 20 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "790328cd3ad64ef2baa3650df893d2f8"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-04-21T18:56:09.584092Z",
          "iopub.status.busy": "2024-04-21T18:56:09.583732Z",
          "iopub.status.idle": "2024-04-21T20:13:22.943827Z",
          "shell.execute_reply": "2024-04-21T20:13:22.942686Z",
          "shell.execute_reply.started": "2024-04-21T18:56:09.584066Z"
        },
        "id": "BknW7BQ3tNn9",
        "outputId": "dc4f6f04-28de-4243-9e3c-4e9320e95ff8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Fine-tune \n",
        "progress_bar = tqdm(total=num_training_steps)\n",
        "\n",
        "ast_model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = ast_model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    average_loss = total_loss / num_batches\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T20:14:01.098444Z",
          "iopub.status.busy": "2024-04-21T20:14:01.097526Z",
          "iopub.status.idle": "2024-04-21T20:14:25.61165Z",
          "shell.execute_reply": "2024-04-21T20:14:25.610638Z",
          "shell.execute_reply.started": "2024-04-21T20:14:01.09841Z"
        },
        "id": "284PbXCGtNn-",
        "outputId": "b038d09a-bdd7-4483-88ed-9ea23a88cfcf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Evaluate the accuracy\n",
        "accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=num_labels)\n",
        "\n",
        "ast_model.eval()\n",
        "for batch in eval_dataloader:\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = ast_model(**batch)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "    # Convert predictions and references to CPU if necessary\n",
        "    predictions = predictions.cpu()\n",
        "    references = batch[\"labels\"].cpu()\n",
        "\n",
        "    # Add batch to Accuracy metric\n",
        "    accuracy.update(predictions, references)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy_result = accuracy.compute()\n",
        "print(\"Accuracy:\", accuracy_result.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model has an accuracy of 0.89 on the test-set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T20:14:35.311629Z",
          "iopub.status.busy": "2024-04-21T20:14:35.310537Z",
          "iopub.status.idle": "2024-04-21T20:14:35.770258Z",
          "shell.execute_reply": "2024-04-21T20:14:35.769418Z",
          "shell.execute_reply.started": "2024-04-21T20:14:35.311571Z"
        },
        "id": "Wetxn1c-tNn_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "torch.save(ast_model.state_dict(), \"trained_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T20:19:03.973189Z",
          "iopub.status.busy": "2024-04-21T20:19:03.972265Z",
          "iopub.status.idle": "2024-04-21T20:19:03.979578Z",
          "shell.execute_reply": "2024-04-21T20:19:03.978507Z",
          "shell.execute_reply.started": "2024-04-21T20:19:03.973155Z"
        },
        "id": "eWBoM_sftNn_",
        "outputId": "26f08408-a3de-457f-e89a-0728aa9cd78f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Doanload model from Kaggle\n",
        "# from IPython.display import FileLink\n",
        "# import os\n",
        "\n",
        "# os.chdir(r'/kaggle/working')\n",
        "# %cd /kaggle/working\n",
        "# FileLink(r'trained_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIH_WiMEtNoE"
      },
      "source": [
        "## Test predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Load ast_model\n",
        "# see here\n",
        "#https://colab.research.google.com/github/YuanGongND/ast/blob/master/colab/AST_Inference_Demo.ipynb#scrollTo=QiB9y5oKUQBV\n",
        "ast_model = ASTForAudioClassification()\n",
        "ast_model.load_state_dict(torch.load(\"trained_model.pth\"))\n",
        "ast_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkawrrEAtNoE"
      },
      "outputs": [],
      "source": [
        "test_input = feature_extractor(df_raw['test'][0]['audio']['array'], sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    processed = ast_model(**test_input, output_attentions=True)\n",
        "\n",
        "predicted_class_ids = torch.argmax(processed.logits, dim=-1).item()\n",
        "predicted_label = ast_model.config.id2label[str(predicted_class_ids)]\n",
        "predicted_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alternative fine-tuning with Huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# batch_size=4\n",
        "\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir = 'ast_gtzan',\n",
        "#     evaluation_strategy = 'epoch',\n",
        "#     save_strategy = 'epoch',\n",
        "#     load_best_model_at_end = True,\n",
        "#     metric_for_best_model = 'accuracy',\n",
        "#     learning_rate = 5e-5,\n",
        "#     seed = SEED,\n",
        "#     per_device_train_batch_size = batch_size,\n",
        "#     per_device_eval_batch_size = batch_size,\n",
        "#     gradient_accumulation_steps = 1,\n",
        "#     num_train_epochs = 15,\n",
        "#     warmup_ratio = 0.1,\n",
        "#     #p16 = True,\n",
        "#     save_total_limit = 2,\n",
        "#     report_to = 'none'\n",
        "#     )\n",
        "\n",
        "# # Loading `accuracy` metric from the evaluate library\n",
        "# metric = load_metric(\"accuracy\")\n",
        "\n",
        "# def compute_metrics(eval_pred):\n",
        "#     \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
        "#     predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "#     return metric.compute(predictions=predictions, references=eval_pred.label_ids)\n",
        "\n",
        "# trainer = Trainer(\n",
        "#      model=ast_model,\n",
        "#      args = training_args,\n",
        "#      train_dataset = df['train'],\n",
        "#      eval_dataset = df['test'],\n",
        "#      tokenizer = feature_extractor,\n",
        "#      compute_metrics = compute_metrics)\n",
        "\n",
        "# trainer.train()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "notebooka62cb2728d",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
