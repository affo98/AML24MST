{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, ASTForAudioClassification, AutoModelForAudioClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset, Audio, load_metric\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://huggingface.co/datasets/marsyas/gtzan\n",
    "df = load_dataset(\"marsyas/gtzan\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df['train'].train_test_split(seed = SEED, shuffle = True, \n",
    "                                  test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining human-readable label\n",
    "id2label_function = df['train'].features['genre'].int2str\n",
    "\n",
    "print(\"genre: \", id2label_function(df['train'][0]['genre']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate_check = None\n",
    "all_same = True\n",
    "\n",
    "# Iterating through each sample\n",
    "for set_name in ['train', 'test']: # Iterating through both sets\n",
    "    for sample in df[set_name]:\n",
    "        sampling_rate = sample['audio']['sampling_rate']\n",
    "\n",
    "        if sampling_rate_check is None:\n",
    "            sampling_rate_check = sampling_rate\n",
    "        else:\n",
    "            if sampling_rate != sampling_rate_check:\n",
    "                all_same = False\n",
    "            break\n",
    "        \n",
    "# Printing result\n",
    "if all_same:\n",
    "    print(f\"All samples have the same sampling rate: {sampling_rate_check} Hz\")\n",
    "else:\n",
    "    print(\"The samples in the dataframe have different sampling rates.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",
    "#model_checkpoint = 'ntu-spml/distilhubert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = feature_extractor.sampling_rate\n",
    "print(f'AST sampling rate: {sampling_rate} Hz')\n",
    "\n",
    "# Resampling data\n",
    "df = df.cast_column(\"audio\", Audio(sampling_rate = 16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of data-points in the array of the audio-files is not exactly the same. So in the feature-extractor we set max_length to 30 seconds and truncate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_duration = 30.0 # 30 seconds\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Extracting and saving arrays \n",
    "    audio_arrays = [x['array'] for x in examples['audio']]\n",
    "    \n",
    "    # Preprocessing audio inputs\n",
    "    inputs = feature_extractor(audio_arrays,\n",
    "                              sampling_rate = feature_extractor.sampling_rate,\n",
    "                              return_tensors=\"pt\", # output pytorch tensors\n",
    "                              max_length = int(feature_extractor.sampling_rate * max_duration),\n",
    "                              truncation = True)\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.map(preprocess_function,\n",
    "                   remove_columns = ['audio', 'file'],\n",
    "                   batched = True,\n",
    "                   batch_size = 100,\n",
    "                   num_proc = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Size of spectogram: {len(df['train'][0]['input_values'][0])}, {len(df['train'][0]['input_values'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming genre column\n",
    "df = df.rename_column('genre', 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Id to label\n",
    "id2label = {str(i): id2label_function(i)\n",
    "           for i in range(len(df['train'].features['labels'].names))}\n",
    "\n",
    "# Label to id\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer = 8 # Defining a random int\n",
    "label = id2label[str(integer)] # Obtaining label \n",
    "\n",
    "print(f'\\nId: {integer}')\n",
    "print(f'\\nLabel: {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(id2label) # Obtaining the total number of labels\n",
    "\n",
    "# Loading model\n",
    "ast_model = AutoModelForAudioClassification.from_pretrained(model_checkpoint,\n",
    "                                                         num_labels = num_labels,\n",
    "                                                         label2id=label2id,\n",
    "                                                         id2label=id2label,\n",
    "                                                         ignore_mismatched_sizes=True)\n",
    "\n",
    "# Visualizing model's architecture\n",
    "print('\\nAST Architecture')\n",
    "print(ast_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=2\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = 'hubert_gtzan',\n",
    "    evaluation_strategy = 'epoch',\n",
    "    save_strategy = 'epoch',\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = 'accuracy',\n",
    "    learning_rate = 5e-5,\n",
    "    seed = SEED,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size = batch_size,\n",
    "    gradient_accumulation_steps = 1,\n",
    "    num_train_epochs = 5,\n",
    "    warmup_ratio = 0.1,\n",
    "    #fp16 = True,\n",
    "    save_total_limit = 2,\n",
    "    report_to = 'none'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading `accuracy` metric from the evaluate library\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=ast_model, \n",
    "    args = training_args,\n",
    "    train_dataset = df['train'],\n",
    "    eval_dataset = df['test'],\n",
    "    tokenizer = feature_extractor,\n",
    "    compute_metrics = compute_metrics)\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
