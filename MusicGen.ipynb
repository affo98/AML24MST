{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"WAryp3o6i3-a"},"outputs":[],"source":["import os\n","os._exit(00)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7aMNVT3-kyaf","executionInfo":{"status":"ok","timestamp":1714489714080,"user_tz":-120,"elapsed":18957,"user":{"displayName":"e okuda","userId":"05819132607139876861"}},"outputId":"63190427-8288-41c4-9fb7-2cc1f3a46e93"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":704,"status":"ok","timestamp":1714489714778,"user":{"displayName":"e okuda","userId":"05819132607139876861"},"user_tz":-120},"id":"HTJu3jflgpmI","outputId":"72282ce9-daaf-43f4-ce01-c968bd1816ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n","Token is valid (permission: read).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["from huggingface_hub import login\n","login(token=\"your_token\")"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["62573b56d58b4315b619cfc2de1b6423","eadb8b45956c4fb8abc771a7032e1f5a","2f4d615d0d224130bdf8c95ea056654a","1233d44e947949678957757bbed5b4e3","f43e4613b9e14e38ac53df3e4c0e666a","bd109119c90b48999aab0525e1f6235b","36a5f3e084a94b9db633444bc3b7abaf","013bf80f1f7d45beb630163e5a8805a6","ac6aa512b12f4373bdbd68cc2cd783d4","b75ccf69765a4546994c96aafdf40592","a9dd31039cd84e07a407d9a6fe7267cc"]},"executionInfo":{"elapsed":15792,"status":"ok","timestamp":1714493487310,"user":{"displayName":"e okuda","userId":"05819132607139876861"},"user_tz":-120},"id":"0GGS-30bs9dx","outputId":"214db5e2-0043-46b1-e011-a4eb9e41d8fc"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62573b56d58b4315b619cfc2de1b6423"}},"metadata":{}}],"source":["from transformers import AutoProcessor, MusicgenForConditionalGeneration, BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer, pipeline\n","\n","prompt = \"\"\"\n","Could you come up with an effective prompt to feed into a LLM to generate the best blues music?\n","\"\"\"\n","\n","model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n","tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n","\n","messages = [\n","    {\"role\": \"user\", \"content\": f\"{prompt}\"},\n","]\n","\n","model_inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to('cpu')"]},{"cell_type":"code","source":["generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n","decoded = tokenizer.batch_decode(generated_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IW8FZ6NUcqQm","executionInfo":{"status":"ok","timestamp":1714493545961,"user_tz":-120,"elapsed":58658,"user":{"displayName":"e okuda","userId":"05819132607139876861"}},"outputId":"250b1f8c-f184-47d1-d93c-5719ef15a3eb"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]}]},{"cell_type":"code","source":["# 1st attempt\n","print(decoded[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tWFrTWumj3jx","executionInfo":{"status":"ok","timestamp":1714493545963,"user_tz":-120,"elapsed":31,"user":{"displayName":"e okuda","userId":"05819132607139876861"}},"outputId":"da195cf9-441c-426b-8337-73b0e10e06d9"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["<s> [INST] \n","Could you come up with an effective prompt to feed into a LLM to generate the best blues music?\n"," [/INST] Sure, here's a prompt that could work:\n","\n","Create a blues track with a slow tempo and a smooth guitar riff playing in the background. The lyrics should consist of a melancholic storytelling about a man feeling down and out, facing a tough situation and trying to hold on. The chorus should be a repeated phrase that conveys a sense of hopelessness and longing, such as \"I'm just a prisoner of the night, singing my soulful song, trying to find some light in this endless dark.\" The music should have a raw and emotional quality, with distorted guitar solos and deep, soulful singing.</s>\n"]}]},{"cell_type":"code","source":["generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n","decoded = tokenizer.batch_decode(generated_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m4nbRQmiSD5S","executionInfo":{"status":"ok","timestamp":1714493554817,"user_tz":-120,"elapsed":8872,"user":{"displayName":"e okuda","userId":"05819132607139876861"}},"outputId":"91261b25-bef5-4d20-8188-cb1b5cfb4007"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]}]},{"cell_type":"code","source":["# 2nd attempt\n","print(decoded[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fqJ4dFvz-Rzg","executionInfo":{"status":"ok","timestamp":1714493554818,"user_tz":-120,"elapsed":37,"user":{"displayName":"e okuda","userId":"05819132607139876861"}},"outputId":"02bc9156-137d-4daf-a80c-59ec287e4c23"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["<s> [INST] \n","Could you come up with an effective prompt to feed into a LLM to generate the best blues music?\n"," [/INST] \"Generate a blues song with a strong melody and emotional lyrics about a broken relationship.\"</s>\n"]}]},{"cell_type":"code","source":["generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n","decoded = tokenizer.batch_decode(generated_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H1gD5WLRSFGR","executionInfo":{"status":"ok","timestamp":1714493572537,"user_tz":-120,"elapsed":17746,"user":{"displayName":"e okuda","userId":"05819132607139876861"}},"outputId":"3c8bd7cf-c870-41f1-bc17-2ce2628b3eea"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]}]},{"cell_type":"code","source":["# 3rd attempt\n","print(decoded[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kvgIbXf3-cNa","executionInfo":{"status":"ok","timestamp":1714493572545,"user_tz":-120,"elapsed":62,"user":{"displayName":"e okuda","userId":"05819132607139876861"}},"outputId":"e8a659d5-f968-4981-b8b3-7aac63790f7e"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["<s> [INST] \n","Could you come up with an effective prompt to feed into a LLM to generate the best blues music?\n"," [/INST] \"Generate a blues song with a strong, expressive melody and soulful lyricism that conveys the emotions of heartache, resilience, and self-discovery.\"</s>\n"]}]},{"cell_type":"code","source":["generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n","decoded = tokenizer.batch_decode(generated_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dnbLcs-2SGNY","executionInfo":{"status":"ok","timestamp":1714493620081,"user_tz":-120,"elapsed":47576,"user":{"displayName":"e okuda","userId":"05819132607139876861"}},"outputId":"6461e5b3-f497-45de-a374-605a030549c8"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]}]},{"cell_type":"code","source":["# 4th attempt\n","print(decoded[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HEOicqxG-gQM","executionInfo":{"status":"ok","timestamp":1714493620087,"user_tz":-120,"elapsed":47,"user":{"displayName":"e okuda","userId":"05819132607139876861"}},"outputId":"950ea60f-bb2c-4709-9997-c8ccc30b2130"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["<s> [INST] \n","Could you come up with an effective prompt to feed into a LLM to generate the best blues music?\n"," [/INST] \"Generate a blues song that captures the feeling of melancholy and the search for hope in the face of adversity. Incorporate the use of common blues motifs such as the twelve-bar blues, rolling chords, and soulful vocals. Make sure the lyrics are authentic and convey the emotion of the music. Bring a bit of your creative flair to the table, but don't stray too far from the blues tradition. Finally, aim to create a piece that will captivate and move the listener.\"</s>\n"]}]},{"cell_type":"code","source":["generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n","decoded = tokenizer.batch_decode(generated_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FQSuZmabSHmL","executionInfo":{"status":"ok","timestamp":1714493663075,"user_tz":-120,"elapsed":43016,"user":{"displayName":"e okuda","userId":"05819132607139876861"}},"outputId":"3687524f-9731-476c-dce4-970c8666e556"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]}]},{"cell_type":"code","source":["# 5th attempt\n","print(decoded[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SaEHlaKX-iwm","executionInfo":{"status":"ok","timestamp":1714493663079,"user_tz":-120,"elapsed":27,"user":{"displayName":"e okuda","userId":"05819132607139876861"}},"outputId":"3752eb4e-6517-4470-b5ea-9ed10c52a4fc"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["<s> [INST] \n","Could you come up with an effective prompt to feed into a LLM to generate the best blues music?\n"," [/INST] Sure, here's a prompt that you could use to generate the best blues music:\n","\n","Prompt: Create a blues music track that tells a story of personal struggle and resilience. Use deep, soulful vocals, rich guitar chords, and a strong, steady rhythm to create an emotive and powerful composition. The lyrics should reflect on a difficult experience or challenge faced, but ultimately convey a message of perseverance and hope in the face of adversity.</s>\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OLrVk2NbdW3s","colab":{"base_uri":"https://localhost:8080/"},"outputId":"179392ca-3438-4ab1-ffeb-f9caa983a461"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","Using the model-agnostic default `max_length` (=1500) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n"]}],"source":["import soundfile as sf\n","import torch\n","\n","prompt1 = \"Create a blues track with a slow tempo and a smooth guitar riff playing in the background. The lyrics should consist of a melancholic storytelling about a man feeling down and out, facing a tough situation and trying to hold on. The chorus should be a repeated phrase that conveys a sense of hopelessness and longing, such as 'I'm just a prisoner of the night, singing my soulful song, trying to find some light in this endless dark.' The music should have a raw and emotional quality, with distorted guitar solos and deep, soulful singing.\"\n","prompt2 = \"Generate a blues song with a strong melody and emotional lyrics about a broken relationship.\"\n","prompt3 = \"Generate a blues song with a strong, expressive melody and soulful lyricism that conveys the emotions of heartache, resilience, and self-discovery.\"\n","prompt4 = \"Generate a blues song that captures the feeling of melancholy and the search for hope in the face of adversity. Incorporate the use of common blues motifs such as the twelve-bar blues, rolling chords, and soulful vocals. Make sure the lyrics are authentic and convey the emotion of the music. Bring a bit of your creative flair to the table, but don't stray too far from the blues tradition. Finally, aim to create a piece that will captivate and move the listener.\"\n","prompt5 = \"Create a blues music track that tells a story of personal struggle and resilience. Use deep, soulful vocals, rich guitar chords, and a strong, steady rhythm to create an emotive and powerful composition. The lyrics should reflect on a difficult experience or challenge faced, but ultimately convey a message of perseverance and hope in the face of adversity\"\n","\n","processor = AutoProcessor.from_pretrained(\"facebook/musicgen-small\")\n","model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n","model = model.half().to('cuda:0')\n","\n","inputs1 = processor(\n","    text=[prompt1],\n","    padding=True,\n","    return_tensors=\"pt\"\n",")\n","inputs1 = inputs1.to('cuda:0')\n","\n","inputs2 = processor(\n","    text=[prompt2],\n","    padding=True,\n","    return_tensors=\"pt\"\n",")\n","inputs2 = inputs2.to('cuda:0')\n","\n","inputs3 = processor(\n","    text=[prompt3],\n","    padding=True,\n","    return_tensors=\"pt\"\n",")\n","inputs3 = inputs3.to('cuda:0')\n","\n","inputs4 = processor(\n","    text=[prompt4],\n","    padding=True,\n","    return_tensors=\"pt\"\n",")\n","inputs4 = inputs4.to('cuda:0')\n","\n","inputs5 = processor(\n","    text=[prompt5],\n","    padding=True,\n","    return_tensors=\"pt\"\n",")\n","inputs5 = inputs5.to('cuda:0')\n","\n","for i in range(0, 20):\n","  audio_values = model.generate(**inputs1)\n","  output_cpu = audio_values[0].cpu().numpy()\n","  output_cpu = output_cpu.squeeze()\n","  output_cpu = output_cpu.astype('float32')\n","  sf.write(f\"/content/drive/MyDrive/MusicGen/Blues/generated_blues{i}.wav\", output_cpu, 22050)\n","\n","for i in range(20, 40):\n","  audio_values = model.generate(**inputs2)\n","  output_cpu = audio_values[0].cpu().numpy()\n","  output_cpu = output_cpu.squeeze()\n","  output_cpu = output_cpu.astype('float32')\n","  sf.write(f\"/content/drive/MyDrive/MusicGen/Blues/generated_blues{i}.wav\", output_cpu, 22050)\n","\n","for i in range(40, 60):\n","  audio_values = model.generate(**inputs3)\n","  output_cpu = audio_values[0].cpu().numpy()\n","  output_cpu = output_cpu.squeeze()\n","  output_cpu = output_cpu.astype('float32')\n","  sf.write(f\"/content/drive/MyDrive/MusicGen/Blues/generated_blues{i}.wav\", output_cpu, 22050)\n","\n","for i in range(60, 80):\n","  audio_values = model.generate(**inputs4)\n","  output_cpu = audio_values[0].cpu().numpy()\n","  output_cpu = output_cpu.squeeze()\n","  output_cpu = output_cpu.astype('float32')\n","  sf.write(f\"/content/drive/MyDrive/MusicGen/Blues/generated_blues{i}.wav\", output_cpu, 22050)\n","\n","for i in range(80, 100):\n","  audio_values = model.generate(**inputs5)\n","  output_cpu = audio_values[0].cpu().numpy()\n","  output_cpu = output_cpu.squeeze()\n","  output_cpu = output_cpu.astype('float32')\n","  sf.write(f\"/content/drive/MyDrive/MusicGen/Blues/generated_blues{i}.wav\", output_cpu, 22050)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52,"output_embedded_package_id":"11GvqIwEH-RcFB8-OOTjCp43D7tv1vcnL"},"executionInfo":{"elapsed":2429,"status":"ok","timestamp":1714134370842,"user":{"displayName":"e okuda","userId":"05819132607139876861"},"user_tz":-120},"id":"Jaehgdgm6fa_","outputId":"65e48448-22fb-4c81-986f-783a1cdfc685"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["#display_audio(audio_values[0], sample_rate=32000)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[],"authorship_tag":"ABX9TyN9LoGEFwnNWMtafNfA69Qt"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"62573b56d58b4315b619cfc2de1b6423":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eadb8b45956c4fb8abc771a7032e1f5a","IPY_MODEL_2f4d615d0d224130bdf8c95ea056654a","IPY_MODEL_1233d44e947949678957757bbed5b4e3"],"layout":"IPY_MODEL_f43e4613b9e14e38ac53df3e4c0e666a"}},"eadb8b45956c4fb8abc771a7032e1f5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd109119c90b48999aab0525e1f6235b","placeholder":"​","style":"IPY_MODEL_36a5f3e084a94b9db633444bc3b7abaf","value":"Loading checkpoint shards: 100%"}},"2f4d615d0d224130bdf8c95ea056654a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_013bf80f1f7d45beb630163e5a8805a6","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ac6aa512b12f4373bdbd68cc2cd783d4","value":2}},"1233d44e947949678957757bbed5b4e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b75ccf69765a4546994c96aafdf40592","placeholder":"​","style":"IPY_MODEL_a9dd31039cd84e07a407d9a6fe7267cc","value":" 2/2 [00:14&lt;00:00,  6.49s/it]"}},"f43e4613b9e14e38ac53df3e4c0e666a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd109119c90b48999aab0525e1f6235b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36a5f3e084a94b9db633444bc3b7abaf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"013bf80f1f7d45beb630163e5a8805a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac6aa512b12f4373bdbd68cc2cd783d4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b75ccf69765a4546994c96aafdf40592":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9dd31039cd84e07a407d9a6fe7267cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}